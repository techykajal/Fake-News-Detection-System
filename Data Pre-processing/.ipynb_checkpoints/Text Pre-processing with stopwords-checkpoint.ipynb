{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kajal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from autocorrect import Speller\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "import timeit\n",
    "stoplist = stopwords.words('english') \n",
    "stoplist = set(stoplist)\n",
    "spell = Speller(lang='en')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Data points :  6335\n",
      "Number of features : 4\n",
      "features : ['Unnamed: 0' 'title' 'text' 'label']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary‚Äôs Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>‚Äî Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary‚Äôs Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  ‚Äî Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Dataset\n",
    "Df = pd.read_csv(r'C:\\Users\\Kajal\\Desktop\\Projects\\Fake_News\\Fake-News-Detection-System\\Dataset\\news.csv')\n",
    "print('Number of Data points : ', Df.shape[0])\n",
    "print('Number of features :', Df.shape[1])\n",
    "print('features :', Df.columns.values)\n",
    "# Show Dataset\n",
    "Df.drop(Df.columns[Df.columns.str.contains('Unnamed: 0',case = False)],axis = 1, inplace = True)\n",
    "Df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6335 entries, 0 to 6334\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   6335 non-null   object\n",
      " 1   text    6335 non-null   object\n",
      " 2   label   6335 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 148.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# This command tells information about the non-null values of attributes of Dataset.\n",
    "Df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You Can Smell Hillary‚Äôs Fear'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df['title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google Pinterest Digg Linkedin Reddit Stumbleupon Print Delicious Pocket Tumblr \\r\\nThere are two fundamental truths in this world: Paul Ryan desperately wants to be president. And Paul Ryan will never be president. Today proved it. \\r\\nIn a particularly staggering example of political cowardice, Paul Ryan re-re-re-reversed course and announced that he was back on the Trump Train after all. This was an aboutface from where he was a few weeks ago. He had previously declared he would not be supporting or defending Trump after a tape was made public in which Trump bragged about assaulting women. Suddenly, Ryan was appearing at a pro-Trump rally and boldly declaring that he already sent in his vote to make him President of the United States. It was a surreal moment. The figurehead of the Republican Party dosed himself in gasoline, got up on a stage on a chilly afternoon in Wisconsin, and lit a match. . @SpeakerRyan says he voted for @realDonaldTrump : ‚ÄúRepublicans, it is time to come home‚Äù https://t.co/VyTT49YvoE pic.twitter.com/wCvSCg4a5I \\r\\n‚Äî ABC News Politics (@ABCPolitics) November 5, 2016 \\r\\nThe Democratic Party couldn‚Äôt have asked for a better moment of film. Ryan‚Äôs chances of ever becoming president went down to zero in an instant. In the wreckage Trump is to leave behind in his wake, those who cravenly backed his campaign will not recover. If Ryan‚Äôs career manages to limp all the way to 2020, then the DNC will have this tape locked and loaded to be used in every ad until Election Day. \\r\\nThe ringing endorsement of the man he clearly hates on a personal level speaks volumes about his own spinelessness. Ryan has postured himself as a ‚Äúprincipled‚Äù conservative, and one uncomfortable with Trump‚Äôs unapologetic bigotry and sexism. However, when push came to shove, Paul Ryan ‚Äì like many of his colleagues ‚Äì turned into a sniveling appeaser. After all his lofty tak about conviction, his principles were a house of cards and collapsed with the slightest breeze. \\r\\nWhat‚Äôs especially bizarre is how close Ryan came to making it through unscathed. For months the Speaker of the House refused to comment on Trump at all. His strategy seemed to be to keep his head down, pretend Trump didn‚Äôt exist, and hope that nobody remembered what happened in 2016. Now, just days away from the election, he screwed it all up. \\r\\nIf 2016‚Äôs very ugly election has done any good it‚Äôs by exposing the utter cowardice of the Republicans who once feigned moral courage. A reality television star spit on them, hijacked their party, insulted their wives, and got every last one of them to kneel before him. What a turn of events. \\r\\nFeatured image via Twitter'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df['text'][1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6335</td>\n",
       "      <td>6335</td>\n",
       "      <td>6335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6256</td>\n",
       "      <td>6060</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>OnPolitics | 's politics blog</td>\n",
       "      <td>Killing Obama administration rules, dismantlin...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>3171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "count                            6335   \n",
       "unique                           6256   \n",
       "top     OnPolitics | 's politics blog   \n",
       "freq                                5   \n",
       "\n",
       "                                                     text label  \n",
       "count                                                6335  6335  \n",
       "unique                                               6060     2  \n",
       "top     Killing Obama administration rules, dismantlin...  REAL  \n",
       "freq                                                   58  3171  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows statistics for every numerical column in our dataset.\n",
    "Df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check type of Dataframe attribute that has to processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type of attribute \"Content\"\n",
    "type(Df['text'])\n",
    "\n",
    "#Type of attribute \"Title\"\n",
    "type(Df['title'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_Emojis(text):\n",
    "    '''\n",
    "    This function will remove all the emojis comes in the text.\n",
    "    \n",
    "    Input: This dog üòÇ\n",
    "    Output: This dog \n",
    "    \n",
    "    '''\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    result = emoji_pattern.sub(r'', text)\n",
    "    return  result # no emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove newlines & tabs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_newlines_tabs(text):\n",
    "    \"\"\"\n",
    "    This function will remove all the occurrences of newlines, tabs, and combinations like: \\\\n, \\\\.\n",
    "    \n",
    "    arguments:\n",
    "        input_text: \"text\" of type \"String\". \n",
    "                    \n",
    "    return:\n",
    "        value: \"text\" after removal of newlines, tabs, \\\\n, \\\\ characters.\n",
    "        \n",
    "    Example:\n",
    "    Input : This is her \\\\ first day at this place.\\n Please,\\t Be nice to her.\\\\n\n",
    "    Output : This is her first day at this place. Please, Be nice to her. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Replacing all the occurrences of \\n,\\\\n,\\t,\\\\ with a space.\n",
    "    Formatted_text = text.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\r',' ').replace('\\t',' ').replace('\\\\', ' ').replace('. com', '.com')\n",
    "    return Formatted_text\n",
    "# len of data :- 1618647 lac words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip Html Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "    \"\"\" \n",
    "    This function will remove all the occurrences of html tags from the text.\n",
    "    \n",
    "    arguments:\n",
    "        input_text: \"text\" of type \"String\". \n",
    "                    \n",
    "    return:\n",
    "        value: \"text\" after removal of html tags.\n",
    "        \n",
    "    Example:\n",
    "    Input : This is a nice place to live. <IMG>\n",
    "    Output : This is a nice place to live.  \n",
    "    \"\"\"\n",
    "    # Initiating BeautifulSoup object soup.\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    # Get all the text other than html tags.\n",
    "    stripped_text = soup.get_text(separator=\" \")\n",
    "    return stripped_text\n",
    "# len of string:- 1616053 lac words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_links(text):\n",
    "    \"\"\"\n",
    "    This function will remove all the occurrences of links.\n",
    "    \n",
    "    arguments:\n",
    "        input_text: \"text\" of type \"String\". \n",
    "                    \n",
    "    return:\n",
    "        value: \"text\" after removal of all types of links.\n",
    "        \n",
    "    Example:\n",
    "    Input : To know more about cats and food & website: catster.com  visit: https://catster.com//how-to-feed-cats\n",
    "    Output : To know more about cats and food & website: visit:     \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Removing all the occurrences of links that starts with https\n",
    "    remove_https = re.sub(r'http\\S+', '', text)\n",
    "    # Remove all the occurrences of text that ends with .com\n",
    "    remove_com = re.sub(r\"\\ [A-Za-z]*\\.com\", \" \", remove_https)\n",
    "    return remove_com\n",
    "# len of words:- 1616053"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove WhiteSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace(text):\n",
    "    \"\"\" This function will remove \n",
    "        extra whitespaces from the text\n",
    "    arguments:\n",
    "        input_text: \"text\" of type \"String\". \n",
    "                    \n",
    "    return:\n",
    "        value: \"text\" after extra whitespaces removed .\n",
    "        \n",
    "    Example:\n",
    "    Input : How   are   you   doing   ?\n",
    "    Output : How are you doing ?     \n",
    "        \n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'\\s+') \n",
    "    Without_whitespace = re.sub(pattern, ' ', text)\n",
    "    # There are some instances where there is no space after '?' & ')', \n",
    "    # So I am replacing these with one space so that It will not consider two words as one token.\n",
    "#     text = Without_whitespace.replace('?', ' ? ').replace(')', ') ')\n",
    "    return text    \n",
    "# len of words:- 1596248 lac words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Remove Accented Characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for accented characters removal\n",
    "def accented_characters_removal(text):\n",
    "    # this is a docstring\n",
    "    \"\"\"\n",
    "    The function will remove accented characters from the \n",
    "    text contained within the Dataset.\n",
    "       \n",
    "    arguments:\n",
    "        input_text: \"text\" of type \"String\". \n",
    "                    \n",
    "    return:\n",
    "        value: \"text\" with removed accented characters.\n",
    "        \n",
    "    Example:\n",
    "    Input : M√°laga, √†√©√™√∂hello\n",
    "    Output : Malaga, aeeohello    \n",
    "        \n",
    "    \"\"\"\n",
    "    # Remove accented characters from text using unidecode.\n",
    "    # Unidecode() - It takes unicode data & tries to represent it to ASCII characters. \n",
    "    text = unidecode.unidecode(text)\n",
    "    return text\n",
    "# Len of data:- 1593952 lac of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Case Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for text lowercasing\n",
    "def lower_casing_text(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    The function will convert text into lower case.\n",
    "    \n",
    "    arguments:\n",
    "         input_text: \"text\" of type \"String\".\n",
    "         \n",
    "    return:\n",
    "         value: text in lowercase\n",
    "         \n",
    "    Example:\n",
    "    Input : The World is Full of Surprises!\n",
    "    Output : the world is full of surprises!\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert text to lower case\n",
    "    # lower() - It converts all upperase letter of given string to lowercase.\n",
    "    text = text.lower()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: Reduce repeated characters and punctuations¬∂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for removing repeated characters and punctuations\n",
    "\n",
    "def reducing_incorrect_character_repeatation(text):\n",
    "    \"\"\"\n",
    "    This Function will reduce repeatition to two characters \n",
    "    for alphabets and to one character for punctuations.\n",
    "    \n",
    "    arguments:\n",
    "         input_text: \"text\" of type \"String\".\n",
    "         \n",
    "    return:\n",
    "        value: Finally formatted text with alphabets repeating to \n",
    "        two characters & punctuations limited to one repeatition \n",
    "        \n",
    "    Example:\n",
    "    Input : Realllllllllyyyyy,        Greeeeaaaatttt   !!!!?....;;;;:)\n",
    "    Output : Reallyy, Greeaatt !?.;:)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Pattern matching for all case alphabets\n",
    "    Pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
    "    \n",
    "    # Limiting all the  repeatation to two characters.\n",
    "    Formatted_text = Pattern_alpha.sub(r\"\\1\\1\", text) \n",
    "    \n",
    "    # Pattern matching for all the punctuations that can occur\n",
    "    Pattern_Punct = re.compile(r'([.,/#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
    "    \n",
    "    # Limiting punctuations in previously formatted string to only one.\n",
    "    Combined_Formatted = Pattern_Punct.sub(r'\\1', Formatted_text)\n",
    "    \n",
    "    # The below statement is replacing repeatation of spaces that occur more than two times with that of one occurrence.\n",
    "    Final_Formatted = re.sub(' {2,}',' ', Combined_Formatted)\n",
    "    return Final_Formatted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation for using some symbols in above regex expression\n",
    "**\\1** ‚Äî> is equivalent to re.search(...). group(1). It Refers to first capturing group. \\1 matches the exact same text that was matched by the first capturing group.\n",
    "\n",
    "**{1,}** --> It means we are matching for repeatation that occurs more than one times. \n",
    "\n",
    "**DOTALL** -> It matches newline character as well unlike dot operator which matches everything in the given text except newline character. \n",
    "\n",
    "**sub()** --> This function is used to replace occurrences of a particular sub-string with another sub-string. This function takes as input the following: The sub-string to replace. The sub-string to replace with.\n",
    "\n",
    "**r'\\1\\1'** --> It limits all the repeatation to two characters.\n",
    "\n",
    "**r'\\1'** --> Limits all the repeatation to only one character.\n",
    "\n",
    "**{2,}** --> It means to match for repeatation that occurs more than two times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: Expand contraction words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\n",
    "\"ain‚Äôt\": \"is not\",\n",
    "\"aren‚Äôt\": \"are not\",\n",
    "\"can‚Äôt\": \"cannot\",\n",
    "\"can‚Äôt‚Äôve\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could‚Äôve\": \"could have\",\n",
    "\"couldn‚Äôt\": \"could not\",\n",
    "\"couldn‚Äôt‚Äôve\": \"could not have\",\n",
    "\"didn‚Äôt\": \"did not\",\n",
    "\"doesn‚Äôt\": \"does not\",\n",
    "\"don‚Äôt\": \"do not\",\n",
    "\"hadn‚Äôt\": \"had not\",\n",
    "\"hadn‚Äôt‚Äôve\": \"had not have\",\n",
    "\"hasn‚Äôt\": \"has not\",\n",
    "\"haven‚Äôt\": \"have not\",\n",
    "\"he‚Äôd\": \"he would\",\n",
    "\"he‚Äôd‚Äôve\": \"he would have\",\n",
    "\"he‚Äôll\": \"he will\",\n",
    "\"he‚Äôll‚Äôve\": \"he he will have\",\n",
    "\"he‚Äôs\": \"he is\",\n",
    "\"how‚Äôd\": \"how did\",\n",
    "\"how‚Äôd‚Äôy\": \"how do you\",\n",
    "\"how‚Äôll\": \"how will\",\n",
    "\"how‚Äôs\": \"how is\",\n",
    "\"i‚Äôd\": \"i would\",\n",
    "\"i‚Äôd‚Äôve\": \"i would have\",\n",
    "\"i‚Äôll\": \"i will\",\n",
    "\"i‚Äôll‚Äôve\": \"i will have\",\n",
    "\"i‚Äôm\": \"i am\",\n",
    "\"i‚Äôve\": \"i have\",\n",
    "\"isn‚Äôt\": \"is not\",\n",
    "\"it‚Äôd\": \"it would\",\n",
    "\"it‚Äôd‚Äôve\": \"it would have\",\n",
    "\"it‚Äôll\": \"it will\",\n",
    "\"it‚Äôll‚Äôve\": \"it will have\",\n",
    "\"it‚Äôs\": \"it is\",\n",
    "\"let‚Äôs\": \"let us\",\n",
    "\"ma‚Äôam\": \"madam\",\n",
    "\"mayn‚Äôt\": \"may not\",\n",
    "\"might‚Äôve\": \"might have\",\n",
    "\"mightn‚Äôt\": \"might not\",\n",
    "\"mightn‚Äôt‚Äôve\": \"might not have\",\n",
    "\"must‚Äôve\": \"must have\",\n",
    "\"mustn‚Äôt\": \"must not\",\n",
    "\"mustn‚Äôt‚Äôve\": \"must not have\",\n",
    "\"needn‚Äôt\": \"need not\",\n",
    "\"needn‚Äôt‚Äôve\": \"need not have\",\n",
    "\"o‚Äôclock\": \"of the clock\",\n",
    "\"oughtn‚Äôt\": \"ought not\",\n",
    "\"oughtn‚Äôt‚Äôve\": \"ought not have\",\n",
    "\"shan‚Äôt\": \"shall not\",\n",
    "\"sha‚Äôn‚Äôt\": \"shall not\",\n",
    "\"shan‚Äôt‚Äôve\": \"shall not have\",\n",
    "\"she‚Äôd\": \"she would\",\n",
    "\"she‚Äôd‚Äôve\": \"she would have\",\n",
    "\"she‚Äôll\": \"she will\",\n",
    "\"she‚Äôll‚Äôve\": \"she will have\",\n",
    "\"she‚Äôs\": \"she is\",\n",
    "\"should‚Äôve\": \"should have\",\n",
    "\"shouldn‚Äôt\": \"should not\",\n",
    "\"shouldn‚Äôt‚Äôve\": \"should not have\",\n",
    "\"so‚Äôve\": \"so have\",\n",
    "\"so‚Äôs\": \"so as\",\n",
    "\"that‚Äôd\": \"that would\",\n",
    "\"that‚Äôd‚Äôve\": \"that would have\",\n",
    "\"that‚Äôs\": \"that is\",\n",
    "\"there‚Äôd\": \"there would\",\n",
    "\"there‚Äôd‚Äôve\": \"there would have\",\n",
    "\"there‚Äôs\": \"there is\",\n",
    "\"they‚Äôd\": \"they would\",\n",
    "\"they‚Äôd‚Äôve\": \"they would have\",\n",
    "\"they‚Äôll\": \"they will\",\n",
    "\"they‚Äôll‚Äôve\": \"they will have\",\n",
    "\"they‚Äôre\": \"they are\",\n",
    "\"they‚Äôve\": \"they have\",\n",
    "\"to‚Äôve\": \"to have\",\n",
    "\"wasn‚Äôt\": \"was not\",\n",
    "\"we‚Äôd\": \"we would\",\n",
    "\"we‚Äôd‚Äôve\": \"we would have\",\n",
    "\"we‚Äôll\": \"we will\",\n",
    "\"we‚Äôll‚Äôve\": \"we will have\",\n",
    "\"we‚Äôre\": \"we are\",\n",
    "\"we‚Äôve\": \"we have\",\n",
    "\"weren‚Äôt\": \"were not\",\n",
    "\"what‚Äôll\": \"what will\",\n",
    "\"what‚Äôll‚Äôve\": \"what will have\",\n",
    "\"what‚Äôre\": \"what are\",\n",
    "\"what‚Äôs\": \"what is\",\n",
    "\"what‚Äôve\": \"what have\",\n",
    "\"when‚Äôs\": \"when is\",\n",
    "\"when‚Äôve\": \"when have\",\n",
    "\"where‚Äôd\": \"where did\",\n",
    "\"where‚Äôs\": \"where is\",\n",
    "\"where‚Äôve\": \"where have\",\n",
    "\"who‚Äôll\": \"who will\",\n",
    "\"who‚Äôll‚Äôve\": \"who will have\",\n",
    "\"who‚Äôs\": \"who is\",\n",
    "\"who‚Äôve\": \"who have\",\n",
    "\"why‚Äôs\": \"why is\",\n",
    "\"why‚Äôve\": \"why have\",\n",
    "\"will‚Äôve\": \"will have\",\n",
    "\"won‚Äôt\": \"will not\",\n",
    "\"won‚Äôt‚Äôve\": \"will not have\",\n",
    "\"would‚Äôve\": \"would have\",\n",
    "\"wouldn‚Äôt\": \"would not\",\n",
    "\"wouldn‚Äôt‚Äôve\": \"would not have\",\n",
    "\"y‚Äôall\": \"you all\",\n",
    "\"y‚Äôall‚Äôd\": \"you all would\",\n",
    "\"y‚Äôall‚Äôd‚Äôve\": \"you all would have\",\n",
    "\"y‚Äôall‚Äôre\": \"you all are\",\n",
    "\"y‚Äôall‚Äôve\": \"you all have\",\n",
    "\"you‚Äôd\": \"you would\",\n",
    "\"you‚Äôd‚Äôve\": \"you would have\",\n",
    "\"you‚Äôll\": \"you will\",\n",
    "\"you‚Äôll‚Äôve\": \"you will have\",\n",
    "\"you‚Äôre\": \"you are\",\n",
    "\"you‚Äôve\": \"you have\",\n",
    "}\n",
    "# The code for expanding contraction words\n",
    "def expand_contractions(text, contraction_mapping =  CONTRACTION_MAP):\n",
    "    \"\"\"expand shortened words to the actual form.\n",
    "       e.g. don't to do not\n",
    "    \n",
    "       arguments:\n",
    "            input_text: \"text\" of type \"String\".\n",
    "         \n",
    "       return:\n",
    "            value: Text with expanded form of shorthened words.\n",
    "        \n",
    "       Example: \n",
    "       Input : ain't, aren't, can't, cause, can't've\n",
    "       Output :  is not, are not, cannot, because, cannot have \n",
    "    \n",
    "     \"\"\"\n",
    "    # Tokenizing text into tokens.\n",
    "    list_Of_tokens = text.split(' ')\n",
    "\n",
    "    # Checking for whether the given token matches with the Key & replacing word with key's value.\n",
    "    \n",
    "    # Check whether Word is in lidt_Of_tokens or not.\n",
    "    for Word in list_Of_tokens: \n",
    "        # Check whether found word is in dictionary \"Contraction Map\" or not as a key. \n",
    "         if Word in CONTRACTION_MAP: \n",
    "                # If Word is present in both dictionary & list_Of_tokens, replace that word with the key value.\n",
    "                list_Of_tokens = [item.replace(Word, CONTRACTION_MAP[Word]) for item in list_Of_tokens]\n",
    "                \n",
    "    # Converting list of tokens to String.\n",
    "    String_Of_tokens = ' '.join(str(e) for e in list_Of_tokens) \n",
    "    return String_Of_tokens     \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5: Remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for removing special characters\n",
    "def removing_special_characters(text):\n",
    "    \"\"\"Removing all the special characters except the one that is passed within \n",
    "       the regex to match, as they have imp meaning in the text provided.\n",
    "   \n",
    "    \n",
    "    arguments:\n",
    "         input_text: \"text\" of type \"String\".\n",
    "         \n",
    "    return:\n",
    "        value: Text with removed special characters that don't require.\n",
    "        \n",
    "    Example: \n",
    "    Input : Hello, K-a-j-a-l. Thi*s is $100.05 : the payment that you will recieve! (Is this okay?) \n",
    "    Output :  Hello, Kajal. This is $100.05 : the payment that you will recieve! Is this okay?\n",
    "    \n",
    "   \"\"\"\n",
    "    # The formatted text after removing not necessary punctuations.\n",
    "    Formatted_Text = re.sub(r\"[^a-zA-Z0-9:$-,%.?!]+\", ' ', text) \n",
    "    # In the above regex expression,I am providing necessary set of punctuations that are frequent in this particular dataset.\n",
    "    return Formatted_Text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuations that I am considering Important as per my Dataset.\n",
    "**,.?!** --> These are some frequent punctuations that occurs a lot and needed to preserved as to understand the context of text.\n",
    "\n",
    "__:__ --> This one is also frequent as per the  Dataset. It is important to keep bcz it is giving sense whenever there is a occurrence of time like: **9:05 p.m.**\n",
    "\n",
    "**%** --> This one is also frequently used in many articles and telling more precisely about the data, facts & figures.\n",
    "\n",
    "**$** --> This one is used in many articles where prices are considered. So, omitting this symbol will not give much sense about those prices that left as just some numbers only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6: Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for removing stopwords\n",
    "stoplist = stopwords.words('english') \n",
    "stoplist = set(stoplist)\n",
    "def removing_stopwords(text):\n",
    "    \"\"\"This function will remove stopwords which doesn't add much meaning to a sentence \n",
    "       & they can be remove safely without comprimising meaning of the sentence.\n",
    "    \n",
    "    arguments:\n",
    "         input_text: \"text\" of type \"String\".\n",
    "         \n",
    "    return:\n",
    "        value: Text after omitted all stopwords.\n",
    "        \n",
    "    Example: \n",
    "    Input : This is Kajal from delhi who came here to study.\n",
    "    Output : [\"'This\", 'Kajal', 'delhi', 'came', 'study', '.', \"'\"] \n",
    "    \n",
    "   \"\"\"\n",
    "    # repr() function actually gives the precise information about the string\n",
    "    text = repr(text)\n",
    "    # Text without stopwords\n",
    "    No_StopWords = [word for word in word_tokenize(text) if word.lower() not in stoplist ]\n",
    "    # Convert list of tokens_without_stopwords to String type.\n",
    "    words_string = ' '.join(No_StopWords)    \n",
    "    return words_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking spellings for all the stopwords "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8: Correct mis-spelled words in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for spelling corrections\n",
    "def spelling_correction(text):\n",
    "    ''' \n",
    "    This function will correct spellings.\n",
    "    \n",
    "    arguments:\n",
    "         input_text: \"text\" of type \"String\".\n",
    "         \n",
    "    return:\n",
    "        value: Text after corrected spellings.\n",
    "        \n",
    "    Example: \n",
    "    Input : This is Oberois from Dlhi who came heree to studdy.\n",
    "    Output : This is Oberoi from Delhi who came here to study.\n",
    "      \n",
    "    \n",
    "    '''\n",
    "    # Check for spellings in English language\n",
    "    spell = Speller(lang='en')\n",
    "    Corrected_text = spell(text)\n",
    "    return Corrected_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7: Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for lemmatization\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatization(text):\n",
    "    \"\"\"This function converts word to their root words \n",
    "       without explicitely cut down as done in stemming.\n",
    "    \n",
    "    arguments:\n",
    "         input_text: \"text\" of type \"String\".\n",
    "         \n",
    "    return:\n",
    "        value: Text having root words only, no tense form, no plural forms\n",
    "        \n",
    "    Example: \n",
    "    Input : text reduced \n",
    "    Output :  text reduce\n",
    "    \n",
    "   \"\"\"\n",
    "    # Converting words to their root forms\n",
    "    lemma = [lemmatizer.lemmatize(w,'v') for w in w_tokenizer.tokenize(text)]\n",
    "    return lemma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step9: Putting all in single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing main function to merge all the preprocessing steps.\n",
    "def text_preprocessing(text, emoticons=True,accented_chars=True, contractions=True, lemma = False,\n",
    "                        extra_whitespace=True, newlines_tabs=True, repeatition=True, \n",
    "                       lowercase=True, punctuations=False, mis_spell=False,\n",
    "                       remove_html=True, links=True,  special_chars=False,\n",
    "                       stop_words=False):\n",
    "    \"\"\"\n",
    "    This function will preprocess input text and return\n",
    "    the clean text.\n",
    "    \"\"\"\n",
    "    if emoticons == True: #remove emojis\n",
    "        Data = remove_Emojis(text)\n",
    "        \n",
    "    if newlines_tabs == True: #remove newlines & tabs.\n",
    "        Data = remove_newlines_tabs(Data)\n",
    "\n",
    "    if remove_html == True: #remove html tags\n",
    "        Data = strip_html_tags(Data)\n",
    "\n",
    "    if links == True: #remove links\n",
    "        Data = remove_links(Data)\n",
    "\n",
    "    if extra_whitespace == True: #remove extra whitespaces\n",
    "        Data = remove_whitespace(Data)\n",
    "\n",
    "    if accented_chars == True: #remove accented characters\n",
    "        Data = accented_characters_removal(Data)\n",
    "\n",
    "    if lowercase == True: #convert all characters to lowercase\n",
    "        Data = lower_casing_text(Data)\n",
    "\n",
    "    if repeatition == True: #Reduce repeatitions   \n",
    "        Data = reducing_incorrect_character_repeatation(Data)\n",
    "\n",
    "    if contractions == True: #expand contractions\n",
    "        Data = expand_contractions(Data)\n",
    "\n",
    "    if punctuations == True: #remove punctuations\n",
    "        Data = removing_special_characters(Data)\n",
    "\n",
    "    stoplist = stopwords.words('english') \n",
    "    stoplist = set(stoplist)\n",
    "    \n",
    "    if stop_words == True: #Remove stopwords\n",
    "        Data = removing_stopwords(Data)\n",
    "\n",
    "    spell = Speller(lang='en')\n",
    "    \n",
    "    if mis_spell == True: #Check for mis-spelled words & correct them.\n",
    "        Data = spelling_correction(Data)\n",
    "\n",
    "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "     \n",
    "    if lemma == True: #Converts words to lemma form.\n",
    "        Data = lemmatization(Data)\n",
    "\n",
    "           \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing for Content\n",
    "List_Content = Df['text'].to_list()\n",
    "Final_Article = []\n",
    "Complete_Content = []\n",
    "for article in List_Content:\n",
    "    Processed_Content = text_preprocessing(article) #Cleaned text of Content attribute after pre-processing\n",
    "    Final_Article.append(Processed_Content)\n",
    "Complete_Content.extend(Final_Article)\n",
    "Df['Processed_Content'] = Complete_Content\n",
    "\n",
    "# Pre-processing for Title\n",
    "List_Title = Df['title'].to_list()\n",
    "\n",
    "Final_Title = []\n",
    "Complete_Title = []\n",
    "for title in List_Title:\n",
    "    Processed_Title = text_preprocessing(title) #Cleaned text of Title attribute after pre-processing\n",
    "    Final_Title.append(Processed_Title)\n",
    "Complete_Title.extend(Final_Title)\n",
    "Df['Processed_Title'] = Complete_Title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Daniel Greenfield, a Shillman Journalism Fello...\n",
       "1       Google Pinterest Digg Linkedin Reddit Stumbleu...\n",
       "2       U.S. Secretary of State John F. Kerry said Mon...\n",
       "3       ‚Äî Kaydee King (@KaydeeKing) November 9, 2016 T...\n",
       "4       It's primary day in New York and front-runners...\n",
       "                              ...                        \n",
       "6330    The State Department told the Republican Natio...\n",
       "6331    The ‚ÄòP‚Äô in PBS Should Stand for ‚ÄòPlutocratic‚Äô ...\n",
       "6332     Anti-Trump Protesters Are Tools of the Oligar...\n",
       "6333    ADDIS ABABA, Ethiopia ‚ÄîPresident Obama convene...\n",
       "6334    Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "Name: text, Length: 6335, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       daniel greenfield, a shillman journalism fello...\n",
       "1       google pinterest digg linkedin reddit stumbleu...\n",
       "2       u.s. secretary of state john f. kerry said mon...\n",
       "3       - kaydee king (@kaydeeking) november 9, 2016 t...\n",
       "4       it's primary day in new york and front-runners...\n",
       "                              ...                        \n",
       "6330    the state department told the republican natio...\n",
       "6331    the 'p' in pbs should stand for 'plutocratic' ...\n",
       "6332     anti-trump protesters are tools of the oligar...\n",
       "6333    addis ababa, ethiopia -president obama convene...\n",
       "6334    jeb bush is suddenly attacking trump. here's w...\n",
       "Name: Processed_Content, Length: 6335, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df['Processed_Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Processed_Content</th>\n",
       "      <th>Processed_Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>the state department told the republican natio...</td>\n",
       "      <td>state department says it can't find emails fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>The ‚ÄòP‚Äô in PBS Should Stand for ‚ÄòPlutocratic‚Äô ...</td>\n",
       "      <td>The ‚ÄòP‚Äô in PBS Should Stand for ‚ÄòPlutocratic‚Äô ...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>the 'p' in pbs should stand for 'plutocratic' ...</td>\n",
       "      <td>the 'p' in pbs should stand for 'plutocratic' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>anti-trump protesters are tools of the oligar...</td>\n",
       "      <td>anti-trump protesters are tools of the oligarc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia ‚ÄîPresident Obama convene...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>addis ababa, ethiopia -president obama convene...</td>\n",
       "      <td>in ethiopia, obama seeks progress on peace, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>jeb bush is suddenly attacking trump. here's w...</td>\n",
       "      <td>jeb bush is suddenly attacking trump. here's w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "6330  State Department says it can't find emails fro...   \n",
       "6331  The ‚ÄòP‚Äô in PBS Should Stand for ‚ÄòPlutocratic‚Äô ...   \n",
       "6332  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text label  \\\n",
       "6330  The State Department told the Republican Natio...  REAL   \n",
       "6331  The ‚ÄòP‚Äô in PBS Should Stand for ‚ÄòPlutocratic‚Äô ...  FAKE   \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE   \n",
       "6333  ADDIS ABABA, Ethiopia ‚ÄîPresident Obama convene...  REAL   \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL   \n",
       "\n",
       "                                      Processed_Content  \\\n",
       "6330  the state department told the republican natio...   \n",
       "6331  the 'p' in pbs should stand for 'plutocratic' ...   \n",
       "6332   anti-trump protesters are tools of the oligar...   \n",
       "6333  addis ababa, ethiopia -president obama convene...   \n",
       "6334  jeb bush is suddenly attacking trump. here's w...   \n",
       "\n",
       "                                        Processed_Title  \n",
       "6330  state department says it can't find emails fro...  \n",
       "6331  the 'p' in pbs should stand for 'plutocratic' ...  \n",
       "6332  anti-trump protesters are tools of the oligarc...  \n",
       "6333  in ethiopia, obama seeks progress on peace, se...  \n",
       "6334  jeb bush is suddenly attacking trump. here's w...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Daniel Greenfield, a Shillman Journalism Fellow at the Freedom Center, is a New York writer focusing on radical Islam. \\r\\nIn the final stretch of the election, Hillary Rodham Clinton has gone to war with the FBI. \\r\\nThe word ‚Äúunprecedented‚Äù has been thrown around so often this election that it ought to be retired. But it‚Äôs still unprecedented for the nominee of a major political party to go war with the FBI. \\r\\nBut that‚Äôs exactly what Hillary and her people have done. Coma patients just waking up now and watching an hour of CNN from their hospital beds would assume that FBI Director James Comey is Hillary‚Äôs opponent in this election. \\r\\nThe FBI is under attack by everyone from Obama to CNN. Hillary‚Äôs people have circulated a letter attacking Comey. There are currently more media hit pieces lambasting him than targeting Trump. It wouldn‚Äôt be too surprising if the Clintons or their allies were to start running attack ads against the FBI. \\r\\nThe FBI‚Äôs leadership is being warned that the entire left-wing establishment will form a lynch mob if they continue going after Hillary. And the FBI‚Äôs credibility is being attacked by the media and the Democrats to preemptively head off the results of the investigation of the Clinton Foundation and Hillary Clinton. \\r\\nThe covert struggle between FBI agents and Obama‚Äôs DOJ people has gone explosively public. \\r\\nThe New York Times has compared Comey to J. Edgar Hoover. Its bizarre headline, ‚ÄúJames Comey Role Recalls Hoover‚Äôs FBI, Fairly or Not‚Äù practically admits up front that it‚Äôs spouting nonsense. The Boston Globe has published a column calling for Comey‚Äôs resignation. Not to be outdone, Time has an editorial claiming that the scandal is really an attack on all women. \\r\\nJames Carville appeared on MSNBC to remind everyone that he was still alive and insane. He accused Comey of coordinating with House Republicans and the KGB. And you thought the ‚Äúvast right wing conspiracy‚Äù was a stretch. \\r\\nCountless media stories charge Comey with violating procedure. Do you know what‚Äôs a procedural violation? Emailing classified information stored on your bathroom server. \\r\\nSenator Harry Reid has sent Comey a letter accusing him of violating the Hatch Act. The Hatch Act is a nice idea that has as much relevance in the age of Obama as the Tenth Amendment. But the cable news spectrum quickly filled with media hacks glancing at the Wikipedia article on the Hatch Act under the table while accusing the FBI director of one of the most awkward conspiracies against Hillary ever. \\r\\nIf James Comey is really out to hurt Hillary, he picked one hell of a strange way to do it. \\r\\nNot too long ago Democrats were breathing a sigh of relief when he gave Hillary Clinton a pass in a prominent public statement. If he really were out to elect Trump by keeping the email scandal going, why did he trash the investigation? Was he on the payroll of House Republicans and the KGB back then and playing it coy or was it a sudden development where Vladimir Putin and Paul Ryan talked him into taking a look at Anthony Weiner‚Äôs computer? \\r\\nEither Comey is the most cunning FBI director that ever lived or he‚Äôs just awkwardly trying to navigate a political mess that has trapped him between a DOJ leadership whose political futures are tied to Hillary‚Äôs victory and his own bureau whose apolitical agents just want to be allowed to do their jobs. \\r\\nThe only truly mysterious thing is why Hillary and her associates decided to go to war with a respected Federal agency. Most Americans like the FBI while Hillary Clinton enjoys a 60% unfavorable rating. \\r\\nAnd it‚Äôs an interesting question. \\r\\nHillary‚Äôs old strategy was to lie and deny that the FBI even had a criminal investigation underway. Instead her associates insisted that it was a security review. The FBI corrected her and she shrugged it off. But the old breezy denial approach has given way to a savage assault on the FBI. \\r\\nPretending that nothing was wrong was a bad strategy, but it was a better one that picking a fight with the FBI while lunatic Clinton associates try to claim that the FBI is really the KGB. \\r\\nThere are two possible explanations. \\r\\nHillary Clinton might be arrogant enough to lash out at the FBI now that she believes that victory is near. The same kind of hubris that led her to plan her victory fireworks display could lead her to declare a war on the FBI for irritating her during the final miles of her campaign. \\r\\nBut the other explanation is that her people panicked. \\r\\nGoing to war with the FBI is not the behavior of a smart and focused presidential campaign. It‚Äôs an act of desperation. When a presidential candidate decides that her only option is to try and destroy the credibility of the FBI, that‚Äôs not hubris, it‚Äôs fear of what the FBI might be about to reveal about her. \\r\\nDuring the original FBI investigation, Hillary Clinton was confident that she could ride it out. And she had good reason for believing that. But that Hillary Clinton is gone. In her place is a paranoid wreck. Within a short space of time the ‚Äúpositive‚Äù Clinton campaign promising to unite the country has been replaced by a desperate and flailing operation that has focused all its energy on fighting the FBI. \\r\\nThere‚Äôs only one reason for such bizarre behavior. \\r\\nThe Clinton campaign has decided that an FBI investigation of the latest batch of emails poses a threat to its survival. And so it‚Äôs gone all in on fighting the FBI. It‚Äôs an unprecedented step born of fear. It‚Äôs hard to know whether that fear is justified. But the existence of that fear already tells us a whole lot. \\r\\nClinton loyalists rigged the old investigation. They knew the outcome ahead of time as well as they knew the debate questions. Now suddenly they are no longer in control. And they are afraid. \\r\\nYou can smell the fear. \\r\\nThe FBI has wiretaps from the investigation of the Clinton Foundation. It‚Äôs finding new emails all the time. And Clintonworld panicked. The spinmeisters of Clintonworld have claimed that the email scandal is just so much smoke without fire. All that‚Äôs here is the appearance of impropriety without any of the substance. But this isn‚Äôt how you react to smoke. It‚Äôs how you respond to a fire. \\r\\nThe misguided assault on the FBI tells us that Hillary Clinton and her allies are afraid of a revelation bigger than the fundamental illegality of her email setup. The email setup was a preemptive cover up. The Clinton campaign has panicked badly out of the belief, right or wrong, that whatever crime the illegal setup was meant to cover up is at risk of being exposed. \\r\\nThe Clintons have weathered countless scandals over the years. Whatever they are protecting this time around is bigger than the usual corruption, bribery, sexual assaults and abuses of power that have followed them around throughout the years. This is bigger and more damaging than any of the allegations that have already come out. And they don‚Äôt want FBI investigators anywhere near it. \\r\\nThe campaign against Comey is pure intimidation. It‚Äôs also a warning. Any senior FBI people who value their careers are being warned to stay away. The Democrats are closing ranks around their nominee against the FBI. It‚Äôs an ugly and unprecedented scene. It may also be their last stand. \\r\\nHillary Clinton has awkwardly wound her way through numerous scandals in just this election cycle. But she‚Äôs never shown fear or desperation before. Now that has changed. Whatever she is afraid of, it lies buried in her emails with Huma Abedin. And it can bring her down like nothing else has.  '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google pinterest digg linkedin reddit stumbleupon print delicious pocket tumblr there are two fundamental truths in this world: paul ryan desperately wants to be president. and paul ryan will never be president. today proved it. in a particularly staggering example of political cowardice, paul ryan re-re-re-reversed course and announced that he was back on the trump train after all. this was an aboutface from where he was a few weeks ago. he had previously declared he would not be supporting or defending trump after a tape was made public in which trump bragged about assaulting women. suddenly, ryan was appearing at a pro-trump rally and boldly declaring that he already sent in his vote to make him president of the united states. it was a surreal moment. the figurehead of the republican party dosed himself in gasoline, got up on a stage on a chilly afternoon in wisconsin, and lit a match. . @speakerryan says he voted for @realdonaldtrump : \"republicans, it is time to come home\" pic.twitter.com/wcvscg4a5i - abc news politics (@abcpolitics) november 5, 2016 the democratic party couldn\\'t have asked for a better moment of film. ryan\\'s chances of ever becoming president went down to zero in an instant. in the wreckage trump is to leave behind in his wake, those who cravenly backed his campaign will not recover. if ryan\\'s career manages to limp all the way to 2020, then the dnc will have this tape locked and loaded to be used in every ad until election day. the ringing endorsement of the man he clearly hates on a personal level speaks volumes about his own spinelessness. ryan has postured himself as a \"principled\" conservative, and one uncomfortable with trump\\'s unapologetic bigotry and sexism. however, when push came to shove, paul ryan - like many of his colleagues - turned into a sniveling appeaser. after all his lofty tak about conviction, his principles were a house of cards and collapsed with the slightest breeze. what\\'s especially bizarre is how close ryan came to making it through unscathed. for months the speaker of the house refused to comment on trump at all. his strategy seemed to be to keep his head down, pretend trump didn\\'t exist, and hope that nobody remembered what happened in 2016. now, just days away from the election, he screwed it all up. if 2016\\'s very ugly election has done any good it\\'s by exposing the utter cowardice of the republicans who once feigned moral courage. a reality television star spit on them, hijacked their party, insulted their wives, and got every last one of them to kneel before him. what a turn of events. featured image via twitter'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df['Processed_Content'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaned_Data = Df.to_csv('Cleaned_Data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
